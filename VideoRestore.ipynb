{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoRestore.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Vkkr1Sq6t2lM"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nak650228/ITEC/blob/main/VideoRestore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkkr1Sq6t2lM"
      },
      "source": [
        "#◢ Video Restoration Project\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "このツールは、Youtubeやローカルファイルから動画をダウンロードし、それをDeepLearningを使って修復します。各処理の修復結果は、ユーザのGoogle Drive上のMovieフォルダに作られます。\n",
        "\n",
        "このツールでは動画に対して以下の修正を試みます。\n",
        "\n",
        "　　・DeOldifyによるモノクロ画像のカラー化\n",
        "\n",
        "　　・Deep Remasterによるノイズ等の除去\n",
        "\n",
        "　　・Microsoft Bringing-Old-Photos-Back-to-LifeまたはGFPGANによる顔画像の修復  \n",
        "\n",
        "　　・音声データの抽出し、動画修正時にそれを結合する\n",
        "\n",
        "　　・オリジナル動画と画像処理後の動画を比較した動画ファイルを作成\n",
        "\n",
        "　　・TecoGANを使った超高解像度化\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1RKQX4WfXdg"
      },
      "source": [
        "#◢ GPUの確認\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "ランタイムに割り当てられたGPUの種類と搭載メモリ容量を確認します。\n",
        "\n",
        "Tesla K80のように搭載メモリが小さなGPUでは、動画の種類によっては実行にエラーを出す場合があるので注意してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7odvNQ3P0KAt",
        "cellView": "form",
        "outputId": "55a1c220-181d-4e49-ffbd-fe68e1790995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title 割り当てられたGPUの確認\n",
        "# Check your current GPU\n",
        "# If you are lucky, you get 16GB VRAM. If you are not lucky, you get less. VRAM is important. The more VRAM, the higher the maximum resolution will go.\n",
        "\n",
        "# 16GB: Can handle 720p. 1080p will procude an out-of-memory error. \n",
        "# 8GB: Can handle 480p. 720p will produce an out-of-memory error.\n",
        "import subprocess\n",
        "\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv\n",
        "gpumem=subprocess.run([\"nvidia-smi\", \"--query-gpu=memory.total\", \"--format=csv,noheader,nounits\"], stdout=subprocess.PIPE, text=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "Tesla K80, 460.32.03, 11441 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0tVaEKkBfg2"
      },
      "source": [
        "#◢ 初期設定\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4HZBs60R08_",
        "cellView": "form"
      },
      "source": [
        "#@title **フラグの設定と最低限必要なライブラリのインポート**\n",
        "IS_DEBUG     = False\n",
        "IS_LIBLOADED = False\n",
        "IS_MSLOADED  = False\n",
        "IS_OLDIFYLOADED  = False\n",
        "IS_GFPGANLOADED  = False\n",
        "IS_DEEPREMASTERLOADED = False\n",
        "IS_TECOGANLOADED = False\n",
        "IS_DAINLOADED = False\n",
        "\n",
        "!pip install youtube_dl\n",
        "import youtube_dl\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import datetime\n",
        "import logging\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import moviepy.editor as mpy\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL23bEM24R4l"
      },
      "source": [
        "#◢ 動画ファイルのダウンロード\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pMiFqHO0hpA",
        "cellView": "form"
      },
      "source": [
        "#@title **Googleドライブのマウント**\n",
        "#@markdown Google ドライブを/content/driveにマウントします。\n",
        "#@markdown このディレクトリの下にMyDrive/Movieというディレクトリがない場合は、それを作ります。\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print('Google Drive connected.')\n",
        "\n",
        "if not os.path.isdir(\"/content/drive/MyDrive/Movie\"):\n",
        "  print(\"Making directory : /content/drive/MyDrive/Movie\")\n",
        "  os.mkdir(\"/content/drive/MyDrive/Movie\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnbyOuhiPEFE"
      },
      "source": [
        "#@title ##**プロジェクト名の入力** { display-mode: \"form\" }\n",
        "#@markdown 任意の名前を入力します。ここで指定した名前のディレクトリ（MyDrive/Movies/指定したプロジェクト名）がGoogle Drive上に作られ、そこに修復された動画がコピーされます。\n",
        "\n",
        "\n",
        "projectname = 'RomanHoliday' #@param {type:\"string\"}\n",
        "\n",
        "projectDir = '/content/drive/MyDrive/Movie/' + projectname\n",
        "if os.path.isdir(projectDir):\n",
        "  print(\"Warning: \" + projectDir + \" is still exist.\")\n",
        "  print(\"Warning: Currnet directory and its contents will be deleted.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaANNxvjMLUZ"
      },
      "source": [
        "#@title ##**ビデオのダウンロード** { display-mode: \"form\" }\n",
        "#@markdown *source_urlフィールドに編集したいビデオのURL（YouTubeやTwitterなど）を入力してください。このフィールドを空白にした場合、ローカルストレージにあるビデオをアップロードできます*\n",
        "#@markdown *プロジェクト名は任意でOKです。一応最後にGoogle Driveにプロジェクト名で指定したディレクトリが作られて、途中経過も含めて全ての動画ファイルがコピーされます*\n",
        "\n",
        "%cd /content\n",
        "! rm -f /content/*.mp4\n",
        "! rm -f /content/*.aac\n",
        "! rm -f /content/*.log\n",
        "\n",
        "# setup logging\n",
        "logger = logging.getLogger('LoggingTest')\n",
        "logger.setLevel(10)\n",
        "fh = logging.FileHandler('/content/restore.log')\n",
        "logger.addHandler(fh)\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s  %(message)s')\n",
        "fh.setFormatter(formatter)\n",
        "\n",
        "log_message='Project Name:     '+projectname\n",
        "logger.info(log_message)\n",
        "\n",
        "source_url = 'https://www.youtube.com/watch?v=mRGuHlczg04&t=79s' #@param {type:\"string\"}\n",
        "\n",
        "if source_url == '':\n",
        "  dt_start_download = datetime.datetime.now()\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  dt_end_download = datetime.datetime.now()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "  os.rename(fn, fn.replace(\" \", \"\"))\n",
        "  fn = fn.replace(\" \", \"\")\n",
        "  file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "  os.rename(fn,file_name)\n",
        "#  !mv -f $fn $file_name\n",
        "  log_message='File Name:       '+fn\n",
        "  logger.info(log_message)\n",
        "\n",
        "else:\n",
        "  try:\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
        "        'outtmpl': 'downloaded_video.mp4',\n",
        "        }\n",
        "    dt_start_download = datetime.datetime.now()\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "      ydl.download([source_url])\n",
        "    dt_end_download = datetime.datetime.now()\n",
        "    file_name = 'downloaded_video.mp4'\n",
        "  \n",
        "  except BaseException:\n",
        "    !wget $source_url\n",
        "    fn = source_url.split('/')[-1]\n",
        "    os.rename(fn, fn.replace(\" \", \"\"))\n",
        "    fn = fn.replace(\" \", \"\")\n",
        "    !mv -f $fn $file_name\n",
        "\n",
        "  log_message='URL:       '+source_url\n",
        "  logger.info(log_message)\n",
        "\n",
        "\n",
        "logger.info('Source file downloaded')\n",
        "\n",
        "!cp -r /content/downloaded_video.mp4 /content/video.mp4\n",
        "\n",
        "\n",
        "fps_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FPS))\n",
        "frames_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "print (\"FPS of VIDEO: \",fps_of_video)\n",
        "print (\"Frames of VIDEO: \",frames_of_video)\n",
        "print (\"Width of VIDEO: \",width_of_video)\n",
        "print (\"Height of VIDEO: \",height_of_video)\n",
        "\n",
        "logger.info('===== Information of video file =====')\n",
        "log_message='FPS of VIDEO:          '+str(fps_of_video)\n",
        "logger.info(log_message)\n",
        "log_message='Frames of VIDEO:       '+str(frames_of_video)\n",
        "logger.info(log_message)\n",
        "log_message='Width of VIDEO:        '+str(width_of_video)\n",
        "logger.info(log_message)\n",
        "log_message='Height of VIDEO:       '+str(height_of_video)\n",
        "logger.info(log_message)\n",
        "logger.info('=====================================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ObdmOuzz13m"
      },
      "source": [
        "#@title ##**動画の調整** { display-mode: \"form\" }\n",
        "\n",
        "#@markdown 　ここではダウンロードした動画にどのような修復を行うかを指定します。\n",
        "\n",
        "#@markdown　**1. 修復範囲の指定**\n",
        "\n",
        "#@markdown まず、以下のtarget_start、target_endにダウンロードした動画のどこからどこまでを修復対象にするか、その開始時間と終了時間を指定してください。\n",
        "\n",
        "\n",
        "target_start = '00:00:53' #@param {type:\"string\"}\n",
        "target_end = '00:00:56' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if os.path.isfile(\"/content/cropped_video.mp4\"):\n",
        "    os.remove(\"/content/cropped_video.mp4\")\n",
        "\n",
        "!ffmpeg -i /content/downloaded_video.mp4  -ss $target_start -to $target_end /content/cropped_video.mp4\n",
        "\n",
        "if os.path.isfile(\"/content/video.mp4\"):\n",
        "    os.remove(\"/content/video.mp4\")\n",
        "\n",
        "!cp /content/cropped_video.mp4 /content/video.mp4\n",
        "\n",
        "##@markdown **インターレスを削除する場合に有効にしてください。**\n",
        "#is_deinterlace = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown　**2. モノクロ動画のカラー化**\n",
        "\n",
        "#@markdown モノクロ動画にAIで色を付ける場合は、以下のチェックボックスを有効にしてください。\n",
        "is_deoldify = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown レンダリングファクターを指定します(お勧めは10～25）。この値により色の付け方が変わります。\n",
        "render_factor = 20  #@param {type: \"slider\", min: 5, max: 44}\n",
        "\n",
        "#@markdown　**3．ノイズ除去**\n",
        "\n",
        "#@markdown 以下のチェックボックスを有効にすると、低画質の動画からノイズなどを除去できます。\n",
        "is_DeepRemaster = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown　**4．顔画像の修復**\n",
        "\n",
        "#@markdown GANを使って、動画の顔部分を書き換えます。この書き換えにはマイクロソフトが開発した 「Bringing-Old-Photos-Back-to-Life」またはテンセントのGFPGANを選択できます。下の入力フィールド右端にある▼をクリックして、どちらを使うか（使わないか）を選択してください。\n",
        "\n",
        "\n",
        "#@markdown お勧めはマイクロソフトですが、顔の検出能力が低いという欠点があります。GFPGANは顔検出が優秀な反面、元の画質が悪いと生成される画像が作り物っぽくなる傾向があります。 \n",
        "which_FaceGAN = 'Microsoft' #@param [\"None\", \"GFPGAN\", \"Microsoft\"] {allow-input: true}\n",
        "\n",
        "\n",
        "\n",
        "#@markdown **5．フレーム補完**\n",
        "\n",
        "#@markdown 一般的な動画は24～30フレーム/秒ですが、動画によってはフレーム数を落としているものがあります。下のチェックボックスを有効にすると、このような動画のフレーム数を2倍に補完して、動きを滑らかにすることができます。\n",
        "is_DAIN = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "file_name=\"/content/cropped_video.mp4\"\n",
        "fps_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FPS))\n",
        "frames_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "log_message='Start:                       '+target_start\n",
        "logger.info(log_message)\n",
        "log_message='End  :                       '+target_end\n",
        "logger.info(log_message)\n",
        "log_message='Oldify:                      '+str(is_deoldify)\n",
        "logger.info(log_message)\n",
        "log_message='Render Factor:               '+str(render_factor)\n",
        "logger.info(log_message)\n",
        "log_message='Deep Remaster:               '+str(is_DeepRemaster)\n",
        "logger.info(log_message)\n",
        "log_message='Type of Face GAN:            '+str(which_FaceGAN)\n",
        "logger.info(log_message)\n",
        "log_message='DAIN :                       '+str(is_DAIN)\n",
        "logger.info(log_message)\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqUFrU1vMiXw"
      },
      "source": [
        "#@title ##**サイズ調整後の動画を表示（修復対象）** { display-mode: \"form\" }\n",
        "\n",
        "#@markdown　ダウンロードした動画から選択された部分を表示します。ここで表示された動画が修復対象となります。\n",
        "\n",
        "#@markdown  下のフィールド右端の▼をクリックして”download\"を選択すると、表示されている動画をダウンロードできます。\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "#  display(mpy.ipython_display(\"/content/video.mp4\", height=400, autoplay=1, maxduration=600))\n",
        "  display(mpy.ipython_display(\"/content/video.mp4\", autoplay=1, maxduration=600, width=640))\n",
        "else:\n",
        "  files.download('/content/video.mp4')\n",
        "\n",
        "print (\"フレームレート: \",fps_of_video)\n",
        "print (\"総フレーム数　: \",frames_of_video)\n",
        "print (\"解像度（横）　: \",width_of_video)\n",
        "print (\"解像度（縦）　: \",height_of_video)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**■メイン処理**\n",
        "入力が終了したら、この行をクリックした後、Runtimeメニューから「以降のセルを実行」または「Run after」を選択してください。\n",
        "\n",
        "以降の行が自動的に実行され修復結果がGoogle Drive上にコピーされます。\n",
        "\n",
        "修復された動画の種類とそのファイル名は以下の通りです。\n",
        "\n",
        "*   downloaded_video.mp4 　　ダウンロードした動画ファイル\n",
        "\n",
        "*   cropped_video.mp4 　　　  ダウンロードした動画から修復対象を抜き出したもの\n",
        "\n",
        "*   upscaled_video.mp4 　　　 cropped_video.mp4の解像度をアップスケールしたもの\n",
        "\n",
        "*   colorized_video.mp4 　　　 モノクロ動画をカラー化したもの\n",
        "\n",
        "*   denoised_video.mp4 　　　 ノイズ除去を行ったもの\n",
        "\n",
        "*   facerestored_video.mp4 　　GANにより顔の修復を行ったもの\n",
        "\n",
        "*   comparison_output.mp4 　　cropped_video.mp4と修復した動画を比較したもの\n",
        "\n",
        "*   final_output.mp4 　　　　　全ての修復を行った結果ファイル（音声付き）\n"
      ],
      "metadata": {
        "id": "UdfplSz7K5m4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc25QNoZbviM"
      },
      "source": [
        "#◢ 関数定義\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2-LWRT7eo42",
        "cellView": "form"
      },
      "source": [
        "#@title 各種関数の定義\n",
        "\n",
        "def decomposit_video(video_folder,video_file, frame_rate):\n",
        "  if os.path.isdir(video_folder):\n",
        "    shutil.rmtree(video_folder)\n",
        "\n",
        "  os.mkdir(video_folder)\n",
        "\n",
        "  os.chdir(video_folder)\n",
        "\n",
        "  decompose_command = 'ffmpeg -i ' + video_file + ' -vf fps=' + str(frame_rate) + ' %09d.png'\n",
        "  subprocess.run(decompose_command, shell=True)\n",
        "  #!ffmpeg -i /content/video.mp4 %09d.png\n",
        "\n",
        "  #clear_output()\n",
        "\n",
        "def composit_video(video_folder, video_file, frame_rate):\n",
        "  if os.path.isfile(video_file):\n",
        "    os.remove(video_file)\n",
        "\n",
        "  compose_command='ffmpeg -f image2 -framerate ' + str(frame_rate) + ' -i ' + video_folder + '/%09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p ' + video_file\n",
        "  subprocess.run(compose_command, shell=True)\n",
        "  #clear_output()\n",
        "\n",
        "def UnSharpMask(image_file, k):\n",
        "    kernel = np.array([[-k/9.0, -k/9.0, -k/9.0],\n",
        "                    [-k/9.0, 1 + (8 * k)/9.0, -k/9.0],\n",
        "                    [-k/9.0, -k/9.0, -k/9.0]])\n",
        "    dst = cv2.filter2D(image_file, -1, kernel)\n",
        "    return dst\n",
        "\n",
        "def make_sharp_kernel(k: int):\n",
        "  return np.array([\n",
        "    [-k / 9, -k / 9, -k / 9],\n",
        "    [-k / 9, 1 + 8 * k / 9, k / 9],\n",
        "    [-k / 9, -k / 9, -k / 9]\n",
        "  ], np.float32)\n",
        "\n",
        "def unsharp_mask_movie(video_folder, video_file, k, frame_rate):\n",
        "  decomposit_video(video_folder,video_file, frame_rate)\n",
        "\n",
        "  files = glob.glob(video_folder+'/*.png')\n",
        "  for ifile in files:\n",
        "    print(\"Now processing \",ifile)\n",
        "    imageblur = cv2.imread(ifile, 0)\n",
        "#    imagesharp = UnSharpMask(imageblur,k)\n",
        "\n",
        "    kernel=make_sharp_kernel(1.0)\n",
        "    imagesharp=cv2.filter2D(imageblur,-1,kernel).astype(\"uint8\")\n",
        "    cv2.imwrite(ifile, imagesharp)\n",
        "\n",
        "  composit_video(video_folder, video_file, frame_rate)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "def load_tensor(image_file):\n",
        "    with Image.open(image_file) as img:\n",
        "        array = np.asarray(img, np.float32).transpose([2, 0, 1]) / 255.0\n",
        "        tensor = torch.as_tensor(np.expand_dims(array, axis=0))  # rank 4\n",
        "    return tensor\n",
        "\n",
        "\n",
        "#def sharpen_filter(image_file):\n",
        "#    kernel = np.array([[-2, -2, -2], [-2, 32, -2], [-2, -2, -2]], np.float32) / 16.0  # convolution filter\n",
        "#    with torch.no_grad():\n",
        "#        # [out_ch, in_ch, .., ..] : channel wiseに計算\n",
        "#        sharpen_k = torch.as_tensor(kernel.reshape(1, 1, 3, 3))\n",
        "#\n",
        "#        color = load_tensor(image_file)  # color image [1, 3, H, W]\n",
        "#        # channel-wise conv(大事)　3x3 convなのでPadding=1を入れる\n",
        "#        multiband = [F.conv2d(color[:, i:i + 1,:,:], sharpen_k, padding=1) for i in range(3)]\n",
        "#        sharpened_image = torch.cat(multiband, dim=1)\n",
        "#        torchvision.utils.save_image(sharpened_image, image_file)\n",
        "\n",
        "def sharpen_filter(image_file, k):\n",
        "  kernel = np.array([[-float(k)/9.0, -float(k)/9.0, -float(k)/9.0],\n",
        "                    [-float(k)/9.0, 1 + (8 * float(k))/9.0, -float(k)/9.0],\n",
        "                    [-float(k)/9.0, -float(k)/9.0, -float(k)/9.0]])\n",
        "  gray = cv2.imread(image_file,0)\n",
        "  dst = cv2.filter2D(gray, -1, kernel)\n",
        "  cv2.imwrite(image_file,dst)\n",
        "  return dst\n",
        "\n",
        "\n",
        "def sharpen_movie(video_folder, video_file, k, frame_rate):\n",
        "  decomposit_video(video_folder,video_file, frame_rate)\n",
        "\n",
        "  files = glob.glob(video_folder+'/*.png')\n",
        "  for ifile in files:\n",
        "    print(\"Now processing \",ifile)\n",
        "    sharpen_filter(ifile, k)\n",
        "\n",
        "  composit_video(video_folder, video_file, frame_rate)\n",
        "\n",
        "\n",
        "#def sharpen_movie(video_folder, video_file, k, frame_rate):\n",
        "#  decomposit_video(video_folder,video_file, frame_rate)\n",
        "#\n",
        "#  files = glob.glob(video_folder+'/*.png')\n",
        "#  for ifile in files:\n",
        "#    print(\"Now processing \",ifile)\n",
        "#    sharpen_filter(ifile)\n",
        "\n",
        "#  composit_video(video_folder, video_file, frame_rate)\n",
        "\n",
        "\n",
        "def hist_filter(image_file):\n",
        "    img = cv2.imread(image_file,0)\n",
        "\n",
        "# create a CLAHE object (Arguments are optional).\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    cl1 = clahe.apply(img)\n",
        "\n",
        "    cv2.imwrite(image_file,cl1)\n",
        "\n",
        "\n",
        "def changehistgram_movie(video_folder, video_file, frame_rate):\n",
        "  decomposit_video(video_folder,video_file, frame_rate)\n",
        "\n",
        "  files = glob.glob(video_folder+'/*.png')\n",
        "  for ifile in files:\n",
        "    print(\"Now processing \",ifile)\n",
        "    hist_filter(ifile)\n",
        "\n",
        "  composit_video(video_folder, video_file, frame_rate)\n",
        "\n",
        "def colorize_video(source_video, output_video, render_factor):\n",
        "  print(source_video)\n",
        "  print(output_video)\n",
        "\n",
        "  if os.path.isfile(\"/content/DeOldify/video\"):\n",
        "    shutil.rmtree(\"/content/DeOldify/video\")\n",
        "\n",
        "  !mkdir -p '/content/DeOldify/video/source'\n",
        "\n",
        "  command1=\"cp -r \" + source_video + \" /content/DeOldify/video/source/video.mp4\"\n",
        "  subprocess.run(command1,shell=True)\n",
        "  print(command1)\n",
        "#  !cp -r str(source_video) /content/DeOldify/video/source/video.mp4\n",
        "  video_path = colorizer.colorize_from_file_name('/content/DeOldify/video/source/video.mp4', render_factor)\n",
        " \n",
        "  command2=\"cp -r /content/DeOldify/video/result/video.mp4 \" + output_video\n",
        "  subprocess.run(command2,shell=True)\n",
        "#  !cp -r /content/DeOldify/video/result/video.mp4 str(output_video)\n",
        "  print(command2)\n",
        "  if os.path.isfile(\"/content/DeOldify/video/result/video.mp4\"):\n",
        "    os.remove(\"/content/DeOldify/video/result/video.mp4\")\n",
        "\n",
        "\n",
        "def clear_logs(flag):\n",
        "  if flag != True:\n",
        "    clear_output()\n",
        "\n",
        "\n",
        "!mkdir /content/reference\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ1FPSlRyxXg",
        "cellView": "form"
      },
      "source": [
        "#@title ライブラリ等のインストール\n",
        "\n",
        "if IS_LIBLOADED != True:\n",
        "\n",
        "  %cd /content\n",
        "\n",
        "  p = os.getenv('PATH')\n",
        "  ld = os.getenv('LD_LIBRARY_PATH')\n",
        "  os.environ['PATH'] = f\"/usr/local/cuda-10.1/bin:{p}\"\n",
        "  os.environ['LD_LIBRARY_PATH'] = f\"/usr/local/cuda-10.1/lib64:{ld}\"\n",
        "\n",
        "  !pip install ffmpeg\n",
        "  !pip install ffmpeg-python\n",
        "  !pip install torch==1.10.0\n",
        "  !pip install torchvision==0.10.1\n",
        "  !pip install scipy\n",
        "  !pip install imgaug\n",
        "\n",
        "  !pip install tensorflow\n",
        "  #!pip install tensorflow==1.15.5\n",
        "  #!pip install imgaug==0.2.5\n",
        "  #!pip install scipy==1.2.0\n",
        "  #!pip install torch==1.4\n",
        "  #!pip install torchvision==0.5\n",
        "\n",
        "  #シーン分割\n",
        "  #!pip install scenedetect[opencv,progress_bar]\n",
        "  #!pip install subprocess\n",
        "\n",
        "  import subprocess\n",
        "  import tensorflow as tf\n",
        "  import ffmpeg\n",
        "  import numpy as np\n",
        "  import imageio\n",
        "  import cv2\n",
        "  import torch\n",
        "  import glob\n",
        "  import shutil\n",
        "  import time\n",
        "  from IPython.display import clear_output\n",
        "\n",
        "\n",
        "  torch.backends.cudnn.benchmark=True\n",
        "\n",
        "#clear_output()\n",
        "  IS_LIBLOADED = True\n",
        "\n",
        "  clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e8z_fE2yLK"
      },
      "source": [
        "# ◢ 音声情報の抽出\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCy-I-yN29Bw",
        "cellView": "form"
      },
      "source": [
        "#@title 音声を抽出し、output.aacという名前で保存\n",
        "if os.path.isfile(\"/content/output.aac\"):\n",
        "  os.remove(\"/content/output.aac\")\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "!ffmpeg -i /content/cropped_video.mp4 -vn -y -acodec copy output.aac\n",
        "clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMvr2lJHhg1L"
      },
      "source": [
        "# ◢ TecoGANによる動画のアップスケール\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vVjUymwetxa"
      },
      "source": [
        "#@title ##**TecoGANのリポジトリをクローンする** { display-mode: \"form\" }\n",
        "\n",
        "if IS_TECOGANLOADED != True :\n",
        "  log_message='Start cloning TecoGAN Repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content\n",
        "  !git clone https://github.com/JoeyBallentine/Video-Inference.git\n",
        "  !git clone https://github.com/skycrapers/TecoGAN-PyTorch.git\n",
        "\n",
        "  %cd /content/TecoGAN-PyTorch/\n",
        "  !bash /content/TecoGAN-PyTorch/scripts/download/download_models.sh BD TecoGAN\n",
        "  !bash /content/TecoGAN-PyTorch/scripts/download/download_models.sh BI TecoGAN\n",
        "  !cp /content/TecoGAN-PyTorch/pretrained_models/* /content/Video-Inference/models/\n",
        "\n",
        "  IS_TECOGANLOADED = True\n",
        "\n",
        "  log_message='Finished cloning TecoGAN Repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8jS-DPT3iq1"
      },
      "source": [
        "#@title ##**動画のアップスケール** { display-mode: \"form\" }\n",
        "if os.path.isfile(\"/content/upscaled_video.mp4\"):\n",
        "  os.remove(\"/content/upscaled_video.mp4\")\n",
        "\n",
        "\n",
        "if height_of_video <= 720: \n",
        "  log_message='Start upscaling with TecoGAN'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content/Video-Inference/\n",
        "  if os.path.isfile(\"./output/video.mp4\"):\n",
        "      os.remove(\"./output/video.mp4\")\n",
        "\n",
        "  !python run.py ./models/TecoGAN_BD_iter500000.pth --input \"/content/video.mp4\" --output \"/content/Video-Inference/output/video.mp4\"\n",
        "\n",
        "  if (height_of_video * 4) >= 1080:\n",
        "    !ffmpeg -i /content/Video-Inference/output/video.mp4 -vf scale=-1:1080 /content/upscaled_video.mp4\n",
        "  else:\n",
        "    !cp ./output/video.mp4 /content/upscaled_video.mp4\n",
        "\n",
        "  !cp /content/upscaled_video.mp4 /content/video.mp4\n",
        "\n",
        "  log_message='Finish upscaling with TecoGAN'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f1MDliBGGGL"
      },
      "source": [
        "# ◢ DeOldifyによるモノクロ動画への彩色\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQLHR6xZleu",
        "cellView": "form"
      },
      "source": [
        "#@title **DeOldifyのリポジトリをクローンする**\n",
        "if IS_OLDIFYLOADED != True and  is_deoldify == True:\n",
        "  log_message='Start cloning DeOldify Repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content\n",
        "\n",
        "  !git clone https://github.com/jantic/DeOldify.git DeOldify\n",
        "  %cd DeOldify\n",
        "\n",
        "  #NOTE:  This must be the first call in order to work properly!\n",
        "  from deoldify import device\n",
        "  from deoldify.device_id import DeviceId\n",
        "  #choices:  CPU, GPU0...GPU7\n",
        "  device.set(device=DeviceId.GPU0)\n",
        "\n",
        "  import torch\n",
        "\n",
        "  if not torch.cuda.is_available():\n",
        "    print('GPU not available.')\n",
        "\n",
        "  from os import path\n",
        "\n",
        "  !pip install -r colab_requirements.txt\n",
        "\n",
        "  import fastai\n",
        "  from deoldify.visualize import *\n",
        "  from pathlib import Path\n",
        "  torch.backends.cudnn.benchmark=True\n",
        "  import warnings\n",
        "  warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")\n",
        "\n",
        "  !mkdir 'models'\n",
        "  !wget https://data.deepai.org/deoldify/ColorizeVideo_gen.pth -O ./models/ColorizeVideo_gen.pth\n",
        "\n",
        "  colorizer = get_video_colorizer()\n",
        "\n",
        "  IS_OLDIFYLOADED = True\n",
        "\n",
        "  log_message='Finish cloning DeOldify Repository'\n",
        "  logger.info(log_message)\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37yAH_olbROZ",
        "cellView": "form"
      },
      "source": [
        "#@title **Deoldifyによるモノクロ動画のカラー化を行う**\n",
        "if is_deoldify == True:\n",
        "  log_message='Start colorization with DeOldify'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content/DeOldify\n",
        "\n",
        "  if os.path.isfile(\"/content/DeOldify/video\"):\n",
        "    shutil.rmtree(\"/content/DeOldify/video\")\n",
        "\n",
        "  !mkdir -p '/content/DeOldify/video/source'\n",
        "\n",
        "  !cp -r /content/video.mp4 /content/DeOldify/video/source/video.mp4\n",
        "  video_path = colorizer.colorize_from_file_name('/content/DeOldify/video/source/video.mp4', render_factor)\n",
        "  !cp -r /content/DeOldify/video/result/video.mp4 /content/colorized_video.mp4\n",
        "  !cp -r /content/colorized_video.mp4 /content/video.mp4\n",
        "  if os.path.isfile(\"/content/DeOldify/video/result/video.mp4\"):\n",
        "    os.remove(\"/content/DeOldify/video/result/video.mp4\")\n",
        "\n",
        "  log_message='Finish colorization with DeOldify'\n",
        "  logger.info(log_message)\n",
        "\n",
        "#colorize_video('/content/video.mp4', '/content/colorized_video.mp4', render_factor)\n",
        "#!cp /content/colorized_video /content/video.mp4\n",
        "clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FakQk0wBE5GS"
      },
      "source": [
        "# ◢ ノイズ除去(Deep Remaster)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqIbGxA_60Oo"
      },
      "source": [
        "#@title ##**DeepRemasterのリポジトリをクローンする** { display-mode: \"form\" }\n",
        "\n",
        "if IS_DEEPREMASTERLOADED != True and is_DeepRemaster == True:\n",
        "  log_message='Start cloning Deep Remaster Repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content\n",
        "  !git clone https://github.com/satoshiiizuka/siggraphasia2019_remastering.git DeepRemaster\n",
        "  !cp -r /content/video.mp4 /content/DeepRemaster/\n",
        "  %cd /content/DeepRemaster\n",
        "\n",
        "  !wget --continue -O model/remasternet.pth.tar -- http://iizuka.cs.tsukuba.ac.jp/data/remasternet.pth.tar\n",
        "\n",
        "  log_message='Finish cloning Deep Remaster Repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  IS_DEEPREMASTERLOADED = True\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzu_lk9DKbTO"
      },
      "source": [
        "#@title ##**画像からノイズを除去する** { display-mode: \"form\" }\n",
        "if os.path.isfile(\"/content/denoised_video.mp4\"):\n",
        "  os.remove(\"/content/denoised_video.mp4\")\n",
        "\n",
        "\n",
        "if is_DeepRemaster == True:\n",
        "\n",
        "  log_message='Start denoising with Deep Remaster'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content/DeepRemaster\n",
        "\n",
        "\n",
        "  #command = \"python remaster.py --input /content/video.mp4 --disable_colorization --gpu --mindim \" + str(int(height_of_video) * 2)\n",
        "  !python remaster.py --input /content/video.mp4 --disable_colorization --gpu --mindim 1080\n",
        "\n",
        "  #subprocess.run(command,shell=True)\n",
        "\n",
        "  !cp /content/video.mp4 /content/denoised_video.mp4\n",
        "#!python remaster.py --input /content/video.mp4 --disable_colorization --gpu --mindim 1080\n",
        "#!python remaster.py --input /content/video.mp4 --disable_colorization --gpu\n",
        "#clear_output()\n",
        "\n",
        "  log_message='Finish denoising with Deep Remaster'\n",
        "  logger.info(log_message)\n",
        "\n",
        "clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tKlt3_S9DgG"
      },
      "source": [
        "#◢ Microsoft Bringing-Old-Photos-Back-to-Lifeによる画像修正\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHeEUq563BHe",
        "cellView": "form"
      },
      "source": [
        "#@title **Microsoft Bringing-Old-Photos-Back-to-Lifeのリポジトリーをクローンする**\n",
        "\n",
        "if IS_MSLOADED != True and which_FaceGAN == \"Microsoft\":\n",
        "\n",
        "  log_message='Start cloning Microsoft Bringing-Old-Photos-Back-to-Life repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content\n",
        "  !git clone https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life.git photo_restoration\n",
        "\n",
        "  #@markdown Microsoft Bringing Old-Photos-Back-to-Lifeの学習済みモデルをダウンロード\n",
        "  # pull the syncBN repo\n",
        "  %cd photo_restoration/Face_Enhancement/models/networks\n",
        "  !git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "  !cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "  %cd ../../../\n",
        "\n",
        "  %cd Global/detection_models\n",
        "  !git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "  !cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "  %cd ../../\n",
        "\n",
        "  # download the landmark detection model\n",
        "  %cd Face_Detection/\n",
        "  !wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "  !bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "  %cd ../\n",
        "\n",
        "  # download the pretrained model\n",
        "  %cd Face_Enhancement/\n",
        "  !wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
        "  !unzip -o checkpoints.zip\n",
        "  %cd ../\n",
        "\n",
        "  %cd Global/\n",
        "  !wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
        "  !unzip -o checkpoints.zip\n",
        "  %cd ../\n",
        "\n",
        "  ! pip install -r requirements.txt\n",
        "  \n",
        "  log_message='Finish cloning Microsoft Bringing-Old-Photos-Back-to-Life repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  IS_MSLOADED = True\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTmlNEoU-END",
        "cellView": "form"
      },
      "source": [
        "#@title **顔画像の修復**\n",
        "# ffmpeg extract - Generating individual frame PNGs from the source file.\n",
        "\n",
        "if os.path.isfile(\"/content/facerestored_video.mp4\"):\n",
        "  os.remove(\"/content/facerestored_video.mp4\")\n",
        "\n",
        "if which_FaceGAN == \"Microsoft\":\n",
        "  log_message='Start face restoration with Microsoft Bringing-Old-Photos-Back-to-Life'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content/photo_restoration\n",
        "\n",
        "  FRAME_INPUT_DIR = \"/content/photo_restoration/input_frames\"\n",
        "  FRAME_OUTPUT_DIR = \"/content/photo_restoration/output_frames\"\n",
        "  INPUT_FILEPATH = \"/content/video.mp4\"\n",
        "\n",
        "  if os.path.isfile(FRAME_INPUT_DIR):\n",
        "     shutil.rmtree(FRAME_INPUT_DIR)\n",
        "  %shell mkdir -p '{FRAME_INPUT_DIR}'\n",
        "       \n",
        "  command = \"ffmpeg -i \" + INPUT_FILEPATH + \" -vf framerate=\" + str(fps_of_video) + \" \" +  FRAME_INPUT_DIR + \"/%05d.png\"\n",
        "  subprocess.run(command,shell=True)\n",
        "\n",
        "#  %shell ffmpeg -i '{INPUT_FILEPATH}' '{FRAME_INPUT_DIR}/%05d.png'\n",
        "\n",
        "  if os.path.isfile(FRAME_OUTPUT_DIR):\n",
        "    shutil.rmtree(FRAME_OUTPUT_DIR)\n",
        "  \n",
        "  %shell mkdir -p '{FRAME_OUTPUT_DIR}'\n",
        "\n",
        "\n",
        "  png_generated_count_command_result = %shell ls '{FRAME_INPUT_DIR}' | wc -l\n",
        "  from IPython.display import clear_output\n",
        "\n",
        "  pngs_generated_count = int(png_generated_count_command_result.output.strip())\n",
        "\n",
        "\n",
        "  #print(f\"Input FPS: {fps}\")\n",
        "  print(f\"{pngs_generated_count} frame PNGs generated.\")\n",
        "\n",
        "  # Checking if PNG do have alpha\n",
        "  import subprocess as sp\n",
        "  %cd {FRAME_INPUT_DIR}\n",
        "  channels = sp.getoutput('identify -format %[channels] 00001.png')\n",
        "  print (f\"{channels} detected\")\n",
        "\n",
        "  # Removing alpha if detected\n",
        "  if \"a\" in channels:\n",
        "    print(\"Alpha detected and will be removed.\")\n",
        "    print(sp.getoutput('find . -name \"*.png\" -exec convert \"{}\" -alpha off PNG24:\"{}\" \\;'))\n",
        "\n",
        "  %cd /content/photo_restoration\n",
        "  input_folder = FRAME_INPUT_DIR\n",
        "  output_folder = FRAME_OUTPUT_DIR\n",
        "\n",
        "  !rm -rf /content/photo_restoration/output_frames/*\n",
        "\n",
        "  print (input_folder)\n",
        "  print (output_folder)\n",
        "\n",
        "  import os\n",
        "  basepath = os.getcwd()\n",
        "  #input_path = os.path.join(basepath, input_folder)\n",
        "  #output_path = os.path.join(basepath, output_folder)\n",
        "  #os.mkdir(output_path)\n",
        "  #!rm -rf output_folder\n",
        "  #os.mkdir(output_folder)\n",
        "\n",
        "  !python run.py --HR --input_folder /content/photo_restoration/input_frames --output_folder /content/photo_restoration/output_frames --GPU 0\n",
        "\n",
        "#create video\n",
        "\n",
        "  %cd /content/photo_restoration/output_frames/final_output\n",
        "  command=\"ffmpeg  -pattern_type glob -i '*.png' -c:v h264_nvenc -pix_fmt yuv420p -framerate \" + str(fps_of_video) + \" /content/facerestored_video.mp4\"\n",
        "  #!ffmpeg  -pattern_type glob -i '*.png' -c:v h264_nvenc -pix_fmt yuv420p /content/facerestored_video.mp4\n",
        "  subprocess.run(command,shell=True)\n",
        "  !rm -f /content/video.mp4\n",
        "  !cp /content/facerestored_video.mp4 /content/video.mp4\n",
        "  #clear_output()\n",
        "\n",
        "  log_message='Finish face restoration with Microsoft Bringing-Old-Photos-Back-to-Life'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbNt7wx9lkd1",
        "cellView": "form"
      },
      "source": [
        "#@title **フレームレートの調整**\n",
        "# Microsoft Bringing-Old-Photos-Back-to-Life では動画をデフォルトで25FPSで作ってしまうため、オリジナルのFPSに変換\n",
        "if which_FaceGAN == \"Microsoft\":\n",
        "  decomposit_video(\"/content/datas\",\"/content/facerestored_video.mp4\", 25)\n",
        "  \n",
        "  composit_video(\"/content/datas\",\"/content/adjusted_video.mp4\",fps_of_video)\n",
        "\n",
        "  !cp /content/adjusted_video.mp4 /content/video.mp4\n",
        "  !rm -f /content/adjusted_video.mp4\n",
        "  \n",
        "  clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smSeEdA4Mv5X"
      },
      "source": [
        "#◢ GFPGANによる顔画像の修復\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwH2ifWEYEfJ",
        "cellView": "form"
      },
      "source": [
        "#@title ##**GFPGANのリポジトリをクローンする**\n",
        "if IS_GFPGANLOADED != True and which_FaceGAN == \"GFPGAN\":\n",
        "\n",
        "  log_message='Start cloning GFPGAN repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  # Clone GFPGAN and enter the GFPGAN folder\n",
        "  %cd /content\n",
        "  !rm -rf GFPGAN\n",
        "  !git clone https://github.com/TencentARC/GFPGAN.git\n",
        "  %cd GFPGAN\n",
        "\n",
        "  # Set up the environment\n",
        "  # Install basicsr - https://github.com/xinntao/BasicSR\n",
        "  # We use BasicSR for both training and inference\n",
        "  !pip install basicsr\n",
        "  # Install facexlib - https://github.com/xinntao/facexlib\n",
        "  # We use face detection and face restoration helper in the facexlib package\n",
        "  !pip install facexlib\n",
        "  # Install other depencencies\n",
        "  !pip install -r requirements.txt\n",
        "  !python setup.py develop\n",
        "  !pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "  # Download the pre-trained model\n",
        "  !wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "  \n",
        "  log_message='Stop cloning GFPGAN repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  IS_GFPGANLOADED = True\n",
        "  \n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzlCT4FRGrGt"
      },
      "source": [
        "#@title ##**GFPGANを使って動画ファイル中の顔画像を修復** { display-mode: \"form\" }\n",
        "\n",
        "if os.path.isfile(\"/content/facerestored_video.mp4\") :\n",
        "  !rm -f /content/facerestored_video.mp4\n",
        "\n",
        "if which_FaceGAN == \"GFPGAN\":\n",
        "  log_message='Start face restoration with GFPGAN'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  !pip install torch==1.10.0 \n",
        "  !pip install torchvision==0.10.1\n",
        "\n",
        "  import os\n",
        "  p = os.getenv('PATH')\n",
        "  ld = os.getenv('LD_LIBRARY_PATH')\n",
        "  os.environ['PATH'] = f\"/usr/local/cuda-10.1/bin:{p}\"\n",
        "  os.environ['LD_LIBRARY_PATH'] = f\"/usr/local/cuda-10.1/lib64:{ld}\"\n",
        "\n",
        "  upload_folder = \"/content/GFPGAN/inputs/upload\"\n",
        "  if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "\n",
        "  os.mkdir(upload_folder)\n",
        "\n",
        "  %cd /content/GFPGAN/inputs/upload\n",
        "\n",
        "  !ffmpeg -i /content/video.mp4 %09d.png\n",
        "\n",
        "# Now we use the GFPGAN to restore the above low-quality images\n",
        "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
        "\n",
        "  %cd /content/GFPGAN\n",
        "  !rm -rf results\n",
        "  !python inference_gfpgan.py --upscale 2 --test_path inputs/upload --save_root results --model_path experiments/pretrained_models/GFPGANCleanv1-NoCE-C2.pth --bg_upsampler realesrgan\n",
        "\n",
        "\n",
        "  command=\"ffmpeg -f image2 -framerate \" + str(fps_of_video) + \" -i /content/GFPGAN/results/restored_imgs/%09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p /content/facerestored_video.mp4 \"\n",
        "  subprocess.run(command,shell=True)\n",
        "  #!ffmpeg -f image2 -framerate 30 -i /content/GFPGAN/results/restored_imgs/%09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p /content/facerestored_video.mp4\n",
        "  !rm -f /content/video.mp4\n",
        "  !cp /content/facerestored_video.mp4 /content/video.mp4\n",
        "\n",
        "  log_message='Finish face restoration with GFPGAN'\n",
        "  logger.info(log_message)\n",
        " \n",
        "  clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYIwa40dJgO4"
      },
      "source": [
        "# ◢ DAINによるフレーム補完\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enAdgSPUgf7J"
      },
      "source": [
        "#@title ##**DAINのリポジトリをクローンする** { display-mode: \"form\" }\n",
        "\n",
        "if IS_DAINLOADED != True and is_DAIN == True:\n",
        "\n",
        "  log_message='Start cloning DAIN repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  %cd /content\n",
        "  !git clone https://github.com/HeylonNHP/Dain-App.git\n",
        "  !pip install ninja\n",
        " # !wget https://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb\n",
        " # !dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb\n",
        "\n",
        "  import os\n",
        "  p = os.getenv('PATH')\n",
        "  ld = os.getenv('LD_LIBRARY_PATH')\n",
        "  os.environ['PATH'] = f\"/usr/local/cuda-10.1/bin:{p}\"\n",
        "  os.environ['LD_LIBRARY_PATH'] = f\"/usr/local/cuda-10.1/lib64:{ld}\"\n",
        "\n",
        "\n",
        "  %cd /content/Dain-App/my_package\n",
        "  !sh build.sh\n",
        "  %cd /content/Dain-App/PWCNet/correlation_package_pytorch1_0\n",
        "  !sh build.sh\n",
        "\n",
        "  !pip install PyQt5\n",
        "  #!sudo add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
        "  #!sudo apt update\n",
        "  #!sudo apt -y install ffmpeg\n",
        "\n",
        "  log_message='Stop cloning DAIN repository'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  IS_DAINLOADED = True\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmSHHkFXnKUE"
      },
      "source": [
        "#@title ##**DAINによるフレーム補完の実行** { display-mode: \"form\" }\n",
        "%cd /content\n",
        "\n",
        "if os.path.isfile(\"/content/interpolated_video.mp4\"):\n",
        "  os.remove(\"/content/interpolated_video.mp4\")\n",
        "\n",
        "if is_DAIN == True:\n",
        "\n",
        "  log_message='Start frame interporation with DAIN'\n",
        "  logger.info(log_message)\n",
        "\n",
        "\n",
        "  %cd /content/Dain-App\n",
        "  !rm -rf /content/Dain-App/example_folder/output_videos/*.mp4\n",
        "\n",
        "  ##!python  my_design.py -cli -h\n",
        "  !cp /content/video.mp4 /content/Dain-App/video.mp4\n",
        "\n",
        "  !python  my_design.py -cli --input \"/content/Dain-App/video.mp4\" -o \"/content/Dain-App/example_folder/\" -on \"/content/interpolated_video.mp4\" -m \"model_weights/best.pth\" -fh 2 --interpolations 2 --depth_awarenes 0 --loop 0 -p 0 --alpha 0 --check_scene_change 10 --png_compress 0 --crf 1 --pixel_upscale_downscale_before 1 --pixel_downscale_upscale_after 1 --pixel_upscale_after 1 --mute_ffmpeg 0 --split_size_x -1 --split_size_y -1 --split_pad 150 --half 0 --step_extract 1 --step_interpolate 1 --batch_size 1 --use_benchmark 0 --force_flow 1 --smooth_flow 0 --downscale -1 --fast_mode 0 -cif 1 -cof 1 -cc 1 -csc 1\n",
        "  ##!python  my_design.py -cli --input \"/content/Dain-App/video.mp4\" -o \"/content/Dain-App/example_folder/\" -on \"interpolated.mp4\" -m \"model_weights/best.pth\" -fh 2 --interpolations 2 --depth_awarenes 0 --loop 0 -p 0 --alpha 0 --check_scene_change 10 --png_compress 0 --crf 1 --pixel_upscale_downscale_before 1 --pixel_downscale_upscale_after 1 --pixel_upscale_after 1 --mute_ffmpeg 0 --split_size_x -1 --split_size_y -1 --split_pad 150 --half 0 --step_extract 1 --step_interpolate 1 --batch_size 1 --use_benchmark 0 --force_flow 1 --smooth_flow 0 --downscale -1 --fast_mode 0\n",
        "  !cp /content/Dain-App/example_folder/output_videos/*.mp4 /content/interpolated_video.mp4\n",
        "  !cp /content/interpolated_video.mp4 /content/video.mp4\n",
        "\n",
        "  log_message='Finish frame interporation with DAIN'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Yy74PQnWUE"
      },
      "source": [
        "#◢ 最終処理\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "051WE5ys5SNy",
        "cellView": "form"
      },
      "source": [
        "#@title 音声のアペンド\n",
        "%cd /content\n",
        "\n",
        "if os.path.isfile(\"/content/final_output.mp4\"):\n",
        "  os.remove(\"/content/final_output.mp4\")\n",
        "  \n",
        "!ffmpeg -i /content/video.mp4 -i /content/output.aac -c:v copy -c:a aac /content/final_output.mp4\n",
        "#!cp /content/final_output.mp4 /content/video.mp4\n",
        "\n",
        "clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8VC7h_9NkQ0",
        "cellView": "form"
      },
      "source": [
        "#@title 比較動画(comparison_output.mp4)の作成\n",
        "if os.path.isfile(\"/content/comparison_output.mp4\"):\n",
        "  os.remove(\"/content/comparison_output.mp4\")\n",
        "\n",
        "if is_DAIN != True:\n",
        "  log_message='Start making comparison video'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  !ffmpeg -i /content/cropped_video.mp4 \\\n",
        "       -i /content/final_output.mp4 \\\n",
        "       -filter_complex \"[0:v]scale=720:-2[v0];[1:v]scale=720:-2[v1];[v0][v1]hstack=inputs=2\" \\\n",
        "       -vcodec libx264 -crf 23 /content/comparison_output.mp4\n",
        "\n",
        "  log_message='Finish making comparison video'\n",
        "  logger.info(log_message)\n",
        "\n",
        "  clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cj0Kxnzi_ah"
      },
      "source": [
        "#@title ##**Google Driveへのファイル・バックアップ** { display-mode: \"form\" }\n",
        "log_message='Start copying results in Google Drive'\n",
        "logger.info(log_message)\n",
        "\n",
        "if os.path.isdir(projectDir):\n",
        "    shutil.rmtree(projectDir)\n",
        "\n",
        "os.mkdir(projectDir)\n",
        "os.chdir(projectDir)\n",
        "!cp /content/*.mp4 .\n",
        "!cp /content/output.aac .\n",
        "\n",
        "!cp /content/restore.log .\n",
        "\n",
        "log_message='Finish copying results in Google Drive'\n",
        "logger.info(log_message)\n",
        "\n",
        "clear_logs(IS_DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#◢ 修復結果の確認\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DqqKGqj8ubgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**修復した動画を表示** { display-mode: \"form\" }\n",
        "\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "#  display(mpy.ipython_display(\"/content/video.mp4\", height=400, autoplay=1, maxduration=600))\n",
        "  display(mpy.ipython_display(\"/content/final_output.mp4\", autoplay=1, maxduration=600, width=640))\n",
        "else:\n",
        "  files.download('/content/video.mp4')\n"
      ],
      "metadata": {
        "id": "QHV0OfIpuimI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}